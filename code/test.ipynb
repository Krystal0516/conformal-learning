{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec26844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.563\n",
      "Average Set Size: 6.827\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect\n",
    "sys.path.insert(1, os.path.join(sys.path[0], './conformal_classification/'))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tdata\n",
    "from conformal import *\n",
    "from utils import *\n",
    "\n",
    "def read_file(File='datasets2022.npz'):\n",
    "    dataset = np.load(File)\n",
    "    # 转换数据形状为 [N, 1, 52, 52]\n",
    "    train_data = dataset['train'].transpose(0, 3, 1, 2)  # 从 [N,52,52,1] 转为 [N,1,52,52]\n",
    "    label_train = dataset['label_train'].astype(np.float32)\n",
    "    return torch.Tensor(train_data), torch.Tensor(label_train)\n",
    "\n",
    "# 加载数据\n",
    "train_data, label_train = read_file()\n",
    "\n",
    "# 只取前1000个样本进行测试\n",
    "train_data = train_data[:1000]\n",
    "label_train = label_train[:1000]\n",
    "\n",
    "# 创建数据集\n",
    "full_dataset = tdata.TensorDataset(train_data, label_train)\n",
    "\n",
    "# 划分校准集和验证集\n",
    "n_data_conf = int(len(full_dataset) * 0.7)  # 70% 作为校准集\n",
    "n_data_val = len(full_dataset) - n_data_conf\n",
    "logits_cal, logits_val = split2(full_dataset, n_data_conf, n_data_val)\n",
    "\n",
    "# 创建数据加载器\n",
    "bsz = 32\n",
    "loader_cal = tdata.DataLoader(logits_cal, batch_size = bsz, shuffle=False, pin_memory=True)\n",
    "loader_val = tdata.DataLoader(logits_val, batch_size = bsz, shuffle=False, pin_memory=True)\n",
    "\n",
    "class ExampleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 输入形状应为 [batch, 1, 52, 52]\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3),      # [batch, 16, 50, 50]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),          # [batch, 16, 25, 25]\n",
    "            nn.Conv2d(16, 32, 3),     # [batch, 32, 23, 23]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)           # [batch, 32, 11, 11]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),             # [batch, 32 * 11 * 11 = 3872]\n",
    "            nn.Linear(3872, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 8)         # 输出8个logits对应8个标签\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.classifier(x)  # 输出形状 [batch, 8]\n",
    "\n",
    "model = ExampleModel()\n",
    "model = model.cuda()  # 若有GPU可用\n",
    "\n",
    "# 初始化共形模型\n",
    "alpha = 0.1  # 期望的覆盖率\n",
    "kreg = None\n",
    "lamda = None\n",
    "randomized = True\n",
    "allow_zero_sets = True\n",
    "pct_paramtune = 0.3\n",
    "lamda_criterion = 'size'\n",
    "\n",
    "conformal_model = ConformalModelMulti(model, loader_cal, alpha=alpha, kreg=kreg, lamda=lamda, randomized=randomized, allow_zero_sets=allow_zero_sets, pct_paramtune=pct_paramtune, lamda_criterion=lamda_criterion)\n",
    "\n",
    "# 验证模型\n",
    "cvg_avg, sz_avg = validate(loader_val, conformal_model, print_bool=True)\n",
    "\n",
    "print(f\"Coverage: {cvg_avg:.3f}\")\n",
    "print(f\"Average Set Size: {sz_avg:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
